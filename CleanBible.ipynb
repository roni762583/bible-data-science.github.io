{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CleanBible.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roni762583/bible-data-science.github.io/blob/master/CleanBible.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "#clone data into datafile\n",
        "! git clone https://github.com/roni762583/bible-data-science.github.io.git\n",
        "# copy my datafile\n",
        "! cp /content/bible-data-science.github.io/data/t3utf.dat datafile\n",
        "# delete unused parts\n",
        "! rm -rf /content/bible-data-science.github.io/\n",
        "! ls -la\n",
        "\n",
        "# Define the string that marks the end of the Torah\n",
        "torah_end_marker = \"אשרעשהמשהלעיניכלישראל\"\n",
        "\n",
        "# Initialize variables\n",
        "s = ''  # to store the clean Hebrew text\n",
        "hebrew_letters = {'א', 'ב', 'ג', 'ד', 'ה', 'ו', 'ז', 'ח', 'ט', 'י', 'כ', 'ך', 'ל', 'מ', 'ם', 'נ', 'ן', 'ס', 'ע', 'פ', 'ף', 'צ', 'ץ', 'ק', 'ר', 'ש', 'ת'}\n",
        "\n",
        "# Open the data file and process line by line\n",
        "with open('datafile', 'r') as file:\n",
        "    for line in file:\n",
        "        # Extract the text part after the last '|' and remove sof-pasuk colon\n",
        "        line = line[line.rfind('|')+1:].replace('׃', '').strip().replace(\" \", \"\")\n",
        "\n",
        "        # Append only valid Hebrew characters to the string 's'\n",
        "        s += ''.join([c for c in line if c in hebrew_letters])\n",
        "\n",
        "        # Check if the end of the Torah has been reached\n",
        "        if torah_end_marker in s:\n",
        "            # Trim the string to end at the Torah marker\n",
        "            s = s[:s.index(torah_end_marker) + len(torah_end_marker)]\n",
        "            break\n",
        "\n",
        "# Save the entire cleaned text up to and including the Torah end marker to a file\n",
        "with open('preprocessed_torah.txt', 'w') as output_file:\n",
        "    output_file.write(s)\n",
        "\n",
        "# Optionally, print the last few characters to verify the Torah end marker\n",
        "print(\"Last few characters in the processed text:\")\n",
        "print(s[-len(torah_end_marker):])  # Should print the Torah end marker\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RQap9BLJSpo3",
        "outputId": "194ec3bd-8958-4c68-9c85-a40f1a32ccac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bible-data-science.github.io'...\n",
            "remote: Enumerating objects: 291, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 291 (delta 75), reused 80 (delta 42), pack-reused 152 (from 1)\u001b[K\n",
            "Receiving objects: 100% (291/291), 10.59 MiB | 15.53 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n",
            "total 5652\n",
            "drwxr-xr-x 1 root root    4096 Aug 27 10:12 .\n",
            "drwxr-xr-x 1 root root    4096 Aug 27 08:47 ..\n",
            "drwxr-xr-x 4 root root    4096 Aug 23 13:20 .config\n",
            "-rw-r--r-- 1 root root 5763655 Aug 27 10:12 datafile\n",
            "drwxr-xr-x 2 root root    4096 Aug 27 09:24 .ipynb_checkpoints\n",
            "drwxr-xr-x 1 root root    4096 Aug 23 13:20 sample_data\n",
            "Last few characters in the processed text:\n",
            "אשרעשהמשהלעיניכלישראל\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fPM24OqZUY9"
      },
      "source": [
        "# Pull off els substrings, offset strings = els\n",
        "\n",
        "def findTermIndeces(text, term):\n",
        "  # print('hello from findTermIndeces()')\n",
        "  indxLst = list()\n",
        "  indx = text.find(term) # index of first occurance of term\n",
        "  while indx != -1: # while term is found in text\n",
        "    indxLst.append(indx) # add index of found term to index list\n",
        "    indx = text.find(term,indx+1) # find next occurance of search term after index of prev. find\n",
        "  return indxLst\n",
        "\n",
        "def searchELS(text, term, minELS, maxELS):\n",
        "  # print('hello from searchELS()')\n",
        "  # initially address positive ELS values only\n",
        "  # ternary-operator\n",
        "  minELS = minELS if minELS>0 else 1\n",
        "  foundTermIndeces = list() # empty list to hold indeces of found search term\n",
        "  results = dict()\n",
        "  elsRng = range(minELS, maxELS)\n",
        "  for els in elsRng:\n",
        "    # print('searching ELS = ', els)\n",
        "    # get ELS substring with offset from 0 to els (current els being examined)\n",
        "    # n = ELS substrings required to cover search space\n",
        "    for offset in range(0, els): # get all offsets from 0 to els\n",
        "      shiftedString = text[offset::els] # get offset string\n",
        "      #foundTermIndeces = foundTermIndeces + findTermIndeces(shiftedString, term) # append new list of indeces to exisiting built list\n",
        "      foundTermIndeces = findTermIndeces(shiftedString, term) # append new list of indeces to exisiting built list\n",
        "      if not (foundTermIndeces): # don't store empty lists\n",
        "        continue\n",
        "      t = tuple([offset, foundTermIndeces]) # store offset to reconstrct indeces, result indeces are of shifted string, not of orig. text\n",
        "      if(els>0): # els 0 is non-sensical, open text is els = 1 here\n",
        "        results[els] = t # add found indeces to dictionary keyed by els\n",
        "      foundTermIndeces = list() # clean out old list\n",
        "  return results\n",
        "# ex:\n",
        "# print(searchELS(s,'עדנה', 0, 17))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx9qjNnPlp45"
      },
      "source": [
        "def findTermIndecesWithOffset(text, term, offset):\n",
        "  # print('hello from findTermIndecesWithOffset()')\n",
        "  indxLst = list()\n",
        "  indx = text.find(term) # index of first occurance of term\n",
        "  while indx != -1: # while term is found in text\n",
        "    offset = offset if offset!=0 else 1\n",
        "    indxLst.append(indx*offset) # add index of found term to index list, THE INDEX IN ORIGINAL TEXT\n",
        "    indx = text.find(term,indx+1) # find next occurance of search term after index of prev. find\n",
        "  return indxLst\n",
        "\n",
        "\n",
        "\n",
        "def searchELSmod(text, term, minELS, maxELS):\n",
        "  # print('hello from searchELS()')\n",
        "  # initially address positive ELS values only\n",
        "  # ternary-operator\n",
        "  minELS = minELS if minELS>0 else 1\n",
        "  foundTermIndeces = list() # empty list to hold indeces of found search term\n",
        "  results = dict()\n",
        "  elsRng = range(minELS, maxELS)\n",
        "  for els in elsRng:\n",
        "    # print('searching ELS = ', els)\n",
        "    # get ELS substring with offset from 0 to els (current els being examined)\n",
        "    # n = ELS substrings required to cover search space\n",
        "    for offset in range(0, els): # get all offsets from 0 to els\n",
        "      shiftedString = text[offset::els] # get offset string\n",
        "      #foundTermIndeces = foundTermIndeces + findTermIndeces(shiftedString, term) # append new list of indeces to exisiting built list\n",
        "      foundTermIndeces = findTermIndecesWithOffset(shiftedString, term, offset) # append new list of indeces to exisiting built list\n",
        "      if not (foundTermIndeces): # don't store empty lists\n",
        "        continue\n",
        "      t = tuple([offset, foundTermIndeces]) # store offset to reconstrct indeces, result indeces are of shifted string, not of orig. text\n",
        "      if(els>0): # els 0 is non-sensical, open text is els = 1 here\n",
        "        results[els] = foundTermIndeces # these indeces are supposed to be equal to the indeces in the original text\n",
        "      foundTermIndeces = list() # clean out old list\n",
        "  return results\n",
        "# ex:\n",
        "# print(searchELS(s,'עדנה', 0, 17))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKeqjU-hVT6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e13ec0-9995-4e82-89ba-3584198e16dc"
      },
      "source": [
        "# get user input for search term\n",
        "term1 = input (\"Enter Primary Search Term:\")\n",
        "print(term1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter Primary Search Term:עדנה\n",
            "עדנה\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWXWujiq8Nv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e685107-13e3-4890-cb54-d85d31740d6a"
      },
      "source": [
        "print(searchELSmod(s, term1, -10, 5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: [21078, 108600, 574590, 835684, 1019725, 1169894], 2: [226804, 435273], 3: [763544], 4: [171879, 173530]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shb6Q07TUHRo",
        "outputId": "b5c5e23f-439c-4b55-800e-5ef0fca41848"
      },
      "source": [
        "# This section deals with reconstructing ELS codes for validation\n",
        "# need to make use of offset value to reconstruct properly\n",
        "# ex:\n",
        "maxELS = 5\n",
        "# get results dict\n",
        "results = searchELSmod(s, term1, 0, maxELS)\n",
        "# helper var\n",
        "builtString = ''\n",
        "# loop over results\n",
        "for k in results: # for each key in results dictionary\n",
        "  for idx in results[k]: # for each index in list\n",
        "    # build print string\n",
        "    for i in range(0, len(term1)):\n",
        "      builtString += s[idx+i*k]\n",
        "    print(builtString)\n",
        "    builtString = ''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "עדנה\n",
            "עדנה\n",
            "עדנה\n",
            "עדנה\n",
            "עדנה\n",
            "עדנה\n",
            "יוול\n",
            "לוקנ\n",
            "קייר\n",
            "מםיא\n",
            "םדנו\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKSTMcW90rMH",
        "outputId": "36ec94ed-ca8f-4c63-f6bc-3e473e46ff33"
      },
      "source": [
        "# write no spaces string to file - only run once\n",
        "text_file = open(\"NoSpacesTanach.dat\", \"w\")\n",
        "text_file.write(s)\n",
        "text_file.close()\n",
        "\n",
        "# delete intermediary datafile\n",
        "! rm datafile\n",
        "\n",
        "#see\n",
        "! ls -la"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 2368\n",
            "drwxr-xr-x 1 root root    4096 Jan 17 05:33 .\n",
            "drwxr-xr-x 1 root root    4096 Jan 17 02:30 ..\n",
            "drwxr-xr-x 1 root root    4096 Jan  8 17:11 .config\n",
            "-rw-r--r-- 1 root root 2405776 Jan 17 05:33 NoSpacesTanach.dat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nAD3QOA4169Z",
        "outputId": "694a2de4-88bd-4cc9-fdf3-aaa26e44767e"
      },
      "source": [
        "# download result file - only run once\n",
        "from google.colab import files\n",
        "files.download('NoSpacesTanach.dat')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_58412f2d-7828-4a12-b0fd-6e4083eb8892\", \"NoSpacesTanach.dat\", 2405776)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}